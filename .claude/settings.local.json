{
  "permissions": {
    "allow": [
      "Bash(find:*)",
      "Bash(pytest:*)",
      "Bash(python3:*)",
      "Bash(grep:*)",
      "Bash(python -m pytest tests/test_write.py -v)",
      "Bash(python -m pytest --tb=short)",
      "Bash(pip install:*)",
      "Bash(python:*)",
      "Bash(pyright:*)",
      "Bash(flake8:*)",
      "Bash(pandoc:*)",
      "Bash(ls:*)",
      "Bash(sed:*)",
      "Bash(jq:*)",
      "WebFetch(domain:qwenlm.github.io)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "Bash(git add OBSOLETE_*.md)",
      "Bash(git add flowchart.md)",
      "Bash(git commit -m \"$(cat <<''EOF''\nUpdate flowchart.md to match current codebase\n\nMajor changes:\n- Add Resume from State flow at the beginning\n- Add NATIVE_LANGUAGE configuration and dynamic prompt loading\n- Add state management (Save Chapter to State)\n- Add OutputFiles structure creation\n- Add PDF generation flow after JSON save\n- Clarify error handling for PDF generation\n\nFlowchart now accurately reflects the complete pipeline including\nPDF generation feature and state management.\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git log --count --grep=\"EXPAND\" --all)",
      "Bash(cat:*)",
      "Bash(python -m pytest:*)",
      "Bash(python -m pytest tests/writer/test_lorebook.py -v)",
      "Bash(pip install langchain)",
      "Bash(python -m pytest tests/writer/test_lorebook.py::TestLorebookManager::test_lorebook_initialization -xvs)",
      "Bash(pip install 'langchain>=0.1.0' 'langchain-community>=0.0.20' chromadb sentence-transformers)",
      "Bash(python -c \"try:\n    from langchain_community.vectorstores import Chroma\n    from langchain_community.embeddings import HuggingFaceEmbeddings\n    from langchain.docstore.document import Document\n    print(''LangChain imports successful'')\nexcept ImportError as e:\n    print(f''Import error: {e}'')\")",
      "Bash(python -m pytest tests/writer/test_lorebook.py::TestLorebookManager::test_add_single_entry -xvs)",
      "Bash(python -c \"from Writer import Config; print(f''USE_LOREBOOK = {Config.USE_LOREBOOK}'')\")",
      "Bash(python -m pytest tests/writer/test_lorebook.py::TestLorebookManager::test_retrieve_character_information -xvs)",
      "Bash(python -m pytest tests/writer/test_lorebook.py::TestLorebookManager::test_add_single_entry -xvs --disable-warnings)",
      "Bash(python -m pytest tests/writer/test_lorebook.py::TestLorebookManager::test_retrieve_character_information -xvs --disable-warnings)",
      "Bash(python -m pytest tests/writer/test_lorebook.py -v --disable-warnings)",
      "Bash(python -m pytest tests/writer/test_lorebook.py::TestLorebookManager::test_extract_from_outline -xvs --disable-warnings)",
      "Bash(python -m pytest tests/test_write.py -k \"test_full_pipeline\" -xvs --disable-warnings)",
      "Bash(python -m pytest tests/test_write.py --collect-only -q)",
      "Bash(python -c \"\n# Test import and basic functionality\nfrom Writer.Pipeline import StoryPipeline\nfrom Writer.Interface import Wrapper\nfrom Writer.PrintUtils import Logger\nfrom Writer import Config\nfrom Writer import Prompts\n\n# Initialize components\nprint(''Initializing interface...'')\ninterface = Wrapper()\nsys_logger = Logger()\nconfig = Config\nactive_prompts = Prompts\n\nprint(''Creating pipeline...'')\npipeline = StoryPipeline(interface, sys_logger, config, active_prompts)\n\nprint(''Checking lorebook integration...'')\nhas_lorebook = hasattr(pipeline, ''lorebook'') and pipeline.lorebook is not None\nprint(f''Lorebook initialized: {has_lorebook}'')\n\nif has_loorebook:\n    # Test lore is accessible\n    stats = pipeline.lorebook.get_stats()\n    print(f''Lorebook stats: {stats}'')\n\nprint(''Integration test successful!'')\n\")",
      "Bash(python -c \"\n# Test import and basic functionality\nfrom Writer.Pipeline import StoryPipeline\nfrom Writer.Interface import Interface\nfrom Writer.PrintUtils import Logger\nfrom Writer import Config\nfrom Writer import Prompts\n\n# Initialize components\nprint(''Initializing interface...'')\ninterface = Interface([])\nsys_logger = Logger()\nconfig = Config\nactive_prompts = Prompts\n\nprint(''Creating pipeline...'')\npipeline = StoryPipeline(interface, sys_logger, config, active_prompts)\n\nprint(''Checking lorebook integration...'')\nhas_lorebook = hasattr(pipeline, ''lorebook'') and pipeline.lorebook is not None\nprint(f''Lorebook initialized: {has_lorebook}'')\n\nif has_lorebook:\n    # Test lore is accessible\n    stats = pipeline.lorebook.get_stats()\n    print(f''Lorebook stats: {stats}'')\n\nprint(''Integration test successful!'')\n\")",
      "Bash(python -c \"\n# Test import and basic functionality\nfrom Writer.Pipeline import StoryPipeline\nfrom Writer.Interface.Wrapper import Interface\nfrom Writer.PrintUtils import Logger\nfrom Writer import Config\nfrom Writer import Prompts\n\n# Initialize components\nprint(''Initializing interface...'')\ninterface = Interface([])\nsys_logger = Logger()\nconfig = Config\nactive_prompts = Prompts\n\nprint(''Creating pipeline...'')\npipeline = StoryPipeline(interface, sys_logger, config, active_prompts)\n\nprint(''Checking lorebook integration...'')\nhas_lorebook = hasattr(pipeline, ''lorebook'') and pipeline.lorebook is not None\nprint(f''Lorebook initialized: {has_lorebook}'')\n\nif has_lorebook:\n    # Test lore is accessible\n    stats = pipeline.lorebook.get_stats()\n    print(f''Lorebook stats: {stats}'')\n\nprint(''Integration test successful!'')\n\")",
      "Bash(python -m pytest tests/writer/test_lorebook.py -q --disable-warnings)",
      "Bash(python -m pytest tests/test_lorebook_integration.py -v --disable-warnings)",
      "Bash(flake8 Writer/Lorebook.py --ignore=E501,W504,W503)",
      "Bash(git add -A)",
      "Bash(git reset HEAD *.txt*)",
      "Bash(git commit -m \"feat: Implement Lorebook system for story consistency\n\n- Add LangChain dependencies (ChromaDB, sentence-transformers)\n- Create LorebookManager class for vector-based lore storage\n- Integrate lorebook into Pipeline for chapter context\n- Add feature flags for enabling/disabling lorebook\n- Add comprehensive tests for lorebook functionality\n- Extract lore from outline automatically\n- Retrieve relevant lore during chapter generation\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\")",
      "Bash(git add .gitignore)",
      "Bash(git commit -m \"chore: Update .gitignore to exclude entire .claude/ directory\n\n.claude/ contains Claude Code system files that should not be tracked\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\")",
      "Bash(python -m pytest tests/writer/test_models.py -v --disable-warnings)",
      "Bash(python -m pytest tests/writer/test_pydantic_integration.py -v --disable-warnings)",
      "Bash(python -m pytest tests/writer/test_pydantic_integration.py tests/writer/test_models.py -v --disable-warnings)",
      "Bash(python -c \"\nfrom Writer.Interface.Wrapper import get_pydantic_format_instructions\nfrom Writer.Models import ChapterOutput, OutlineOutput\n\n# Test ChapterOutput format instructions\nprint(''=== ChapterOutput Format Instructions ==='')\ninstructions = get_pydantic_format_instructions(ChapterOutput)\nprint(instructions[:500] + ''...'' if len(instructions) > 500 else instructions)\n\nprint(''\\n=== OutlineOutput Format Instructions ==='')\ninstructions = get_pydantic_format_instructions(OutlineOutput)\nprint(instructions[:500] + ''...'' if len(instructions) > 500 else instructions)\n\")",
      "Bash(python -c \"\n# Test importing the modified chapter generator\nimport Writer.Chapter.ChapterGenerator as CG\nimport Writer.Config as Config\n\nprint(''ChapterGenerator imported successfully'')\nprint(f''USE_PYDANTIC_PARSING = {Config.USE_PYDANTIC_PARSING}'')\n\n# Test the helper function\nfrom Writer.Interface.Wrapper import Interface\nfrom Writer.PrintUtils import Logger\n\ninterface = Interface()\nlogger = Logger()\nresult = CG._get_pydantic_format_instructions_if_enabled(interface, logger, Config)\nprint(f''Pydantic instructions generated: {len(result) > 0 if result else False}'')\n\")",
      "Bash(python -m pytest tests/writer/test_reasoning_chain.py -v --disable-warnings)",
      "Bash(python -c \"\nimport ast\ntry:\n    with open(''/var/www/AIStoryWriter/Writer/ReasoningChain.py'', ''r'') as f:\n        source = f.read()\n    ast.parse(source)\n    print(''Syntax is valid'')\nexcept SyntaxError as e:\n    print(f''Syntax error at line {e.lineno}: {e.text}'')\n    print(f''Error: {e.msg}'')\n\")",
      "WebFetch(domain:github.com)",
      "Bash(python -c \"\n# Test that structured output is working with Ollama\nfrom Writer.Interface.Wrapper import Interface\nfrom Writer.Models import ChapterOutput\nfrom Writer.PrintUtils import Logger\nimport Writer.Config as Config\n\nprint(''Testing Ollama structured output with Pydantic verification...'')\nprint(f''USE_PYDANTIC_PARSING: {Config.USE_PYDANTIC_PARSING}'')\n\n# Check if we have Ollama models\ninterface = Interface()\nollama_models = [k for k in interface.Clients.keys() if ''ollama'' in k.lower()]\nprint(f''Ollama clients found: {ollama_models}'')\n\nif ollama_models:\n    # Test the format parameter is passed correctly\n    import inspect\n    source = inspect.getsource(interface._ollama_chat)\n    if ''format:\"\"json\"\"'' in source:\n        print(''âœ“ Ollama format parameter for JSON is configured'')\n    if ''_FormatSchema_dict'' in source:\n        print(''âœ“ Format schema parameter is properly handled'')\n\")",
      "Bash(python -m pytest tests/test_langchain_integration.py -v --disable-warnings)",
      "Bash(python -c \"\nimport Writer.Prompts as Prompts\nprint(''CHAPTER_GENERATION_STAGE1 has PydanticFormatInstructions:'', ''{PydanticFormatInstructions}'' in Prompts.CHAPTER_GENERATION_STAGE1)\nprint(''CHAPTER_GENERATION_STAGE2 has PydanticFormatInstructions:'', ''{PydanticFormatInstructions}'' in Prompts.CHAPTER_GENERATION_STAGE2)\nprint(''CHAPTER_GENERATION_STAGE3 has PydanticFormatInstructions:'', ''{PydanticFormatInstructions}'' in Prompts.CHAPTER_GENERATION_STAGE3)\n\")",
      "Bash(python -m pytest tests/test_e2e_enhancements.py -v --disable-warnings)",
      "Bash(python -m pytest tests/writer/test_lorebook.py tests/writer/test_models.py tests/writer/test_pydantic_integration.py tests/writer/test_reasoning_chain.py tests/test_langchain_integration.py -v --disable-warnings -q)",
      "Bash(python examples/enhanced_generation.py)",
      "WebSearch",
      "WebFetch(domain:ai.google.dev)",
      "WebFetch(domain:openrouter.ai)",
      "WebFetch(domain:api.github.com)",
      "WebFetch(domain:pypi.org)",
      "Bash(python -m pytest tests/writer/interface/test_wrapper_embedding.py -v)",
      "Bash(python -m pytest tests/writer/test_lorebook.py -v --tb=short)",
      "Bash(python -m pytest tests/writer/interface/test_wrapper_embedding.py -v --tb=short)",
      "Bash(find Writer/ -name \"*.py\" -exec grep -h \"^import\\|^from\" {})",
      "Bash(chmod +x /var/www/AIStoryWriter/clean_python_env.sh)",
      "Bash(find /var/www/AIStoryWriter -name \"*.py\" -exec grep -l \"from pydantic import\" {})",
      "Bash(python -m pytest tests/writer/test_lorebook_deprecation.py -v)",
      "Bash(python -m pytest tests/writer/test_lorebook_deprecation.py::test_lorebook_uses_langchain_chroma_preferentially -v)",
      "Bash(python -m pytest tests/writer/test_lorebook_deprecation.py::test_lorebook_imports_chroma_without_deprecation -v -s)",
      "Bash(python -c \"\nimport warnings\nwarnings.simplefilter(''''always'''')\nfrom Writer.Lorebook import LorebookManager\n\")",
      "Bash(python -c \"\nimport Writer.Config as Config\nConfig.EMBEDDING_MODEL = ''ollama://nomic-embed-text:latest''\nConfig.USE_LOREBOOK = True\nimport warnings\nwarnings.simplefilter(''always'')\nfrom Writer.Lorebook import LorebookManager\n\")",
      "Bash(python -m pytest tests/writer/interface/test_ollama_host_parsing.py -v)",
      "Bash(python -m pytest tests/writer/interface/test_ollama_host_parsing.py -v -s)",
      "Bash(python -c \"import Writer.Config as Config; print(''OLLAMA_HOST ='', getattr(Config, ''OLLAMA_HOST'', ''NOT SET''))\")",
      "Bash(python -c \"\n# Test to see how the JSON output flows\nimport Writer.Config as Config\nConfig.DEBUG = False\nfrom Writer.Interface.Wrapper import Interface\nfrom Writer.PrintUtils import Logger\ninterface = Interface([])\n\n# Mock a simple JSON response\ntest_messages = [{''role'': ''user'', ''content'': ''Respond with ONLY the JSON object: {\\\"\"IsComplete\\\"\": true}''}]\n\n# This will show if the JSON gets printed during the call\nprint(''=== Before SafeGenerateJSON ==='')\n_, result, _ = interface.SafeGenerateJSON(Logger(), test_messages, ''test://model'')\nprint(''=== After SafeGenerateJSON ==='')\nprint(f''Result: {result}'')\n\")",
      "Bash(python -m pytest tests/writer/interface/test_json_output_display.py -v -s)",
      "Bash(python -m pytest tests/writer/interface/test_json_output_display.py::test_json_output_not_displayed -v -s)",
      "Bash(python -m pytest tests/writer/interface/test_json_output_display.py -v)",
      "Bash(python -m pytest tests/writer/test_lorebook_deprecation.py tests/writer/interface/test_ollama_host_parsing.py tests/writer/interface/test_json_output_display.py -v)",
      "Bash(python -m pytest tests/writer/test_language_consistency.py -v -s)",
      "Bash(python -m pytest tests/writer/test_language_consistency.py -v)",
      "Bash(python -m pytest tests/writer/test_language_consistency.py::test_prompt_imports_respect_language tests/writer/test_language_consistency.py::test_language_consistency_across_modules -v)",
      "Bash(python -m pytest tests/writer/test_language_prompt_usage.py -v -s)",
      "Bash(python -m pytest tests/writer/test_word_count_validation.py::test_word_count_validation_default_tolerance -v)",
      "Bash(python -m pytest tests/writer/test_word_count_validation.py::test_configurable_tolerance_in_values -v)",
      "Bash(python -c \"\ntext = ''This is a much longer test chapter that contains significantly more words than the specified count and should exceed the tolerance threshold by a considerable margin making it fail validation because the difference is too large.''\nprint(f''Word count: {len(text.split())}'')\nprint(f''Text: {text}'')\n\")",
      "Bash(python -c \"\ntext = ''This is a much longer test chapter that contains significantly more words than the specified count. It has way too many words and should exceed the tolerance threshold by a considerable margin making it fail validation because the difference is too large. Adding more text here to ensure it goes over the fifty word tolerance limit.''\nprint(f''Word count: {len(text.split())}'')\n\")",
      "Bash(python -c \"\nimport Writer.Config as Config\nprint(f''PYDANTIC_WORD_COUNT_TOLERANCE: {getattr(Config, \"\"PYDANTIC_WORD_COUNT_TOLERANCE\"\", \"\"NOT FOUND\"\")}'')\n\nfrom Writer.Models import ChapterOutput\n\n# Test the validator directly\ntry:\n    chapter = ChapterOutput(\n        text=''This is a much longer test chapter that contains significantly more words than the specified count. It has way too many words and should exceed the tolerance threshold by a considerable margin making it fail validation because the difference is too large. Adding more text here to ensure it goes over the fifty word tolerance limit.'',\n        word_count=10,\n        chapter_number=1\n    )\n    print(f''Chapter created successfully with word_count: {chapter.word_count}'')\nexcept Exception as e:\n    print(f''Error: {e}'')\n\")",
      "Bash(python -c \"import pydantic; print(f''Pydantic version: {pydantic.__version__}'')\")",
      "Bash(python -c \"\nfrom pydantic import ValidationError\nfrom Writer.Models import ChapterOutput\n\ntry:\n    chapter = ChapterOutput(\n        text=''This is a much longer test chapter that contains significantly more words than the specified count. It has way too many words and should exceed the tolerance threshold by a considerable margin making it fail validation because the difference is too large. Adding more text here to ensure it goes over the fifty word tolerance limit.'',\n        word_count=10,\n        chapter_number=1\n    )\n    actual_words = len(chapter.text.split())\n    print(f''Chapter created!'')\n    print(f''Word count field: {chapter.word_count}'')\n    print(f''Actual words: {actual_words}'')\n    print(f''Difference: {abs(chapter.word_count - actual_words)}'')\n    \n    import Writer.Config as Config\n    print(f''Tolerance: {Config.PYDANTIC_WORD_COUNT_TOLERANCE}'')\n    \nexcept ValidationError as e:\n    print(f''ValidationError caught: {e}'')\nexcept Exception as e:\n    print(f''Other error: {e}'')\n\")",
      "Bash(python -c \"text=''This is a much longer test chapter that contains significantly more words than the specified count. It has way too many words and should exceed the tolerance threshold by a considerable margin making it fail validation because the difference is too large. Adding more text here to ensure it goes over the fifty word tolerance limit by a lot. More words are needed here. Even more words. And some extra words just to be sure. This should definitely exceed the tolerance limit now.''; print(f''Word count: {len(text.split())}'')\")",
      "Bash(python -m pytest tests/writer/test_word_count_validation.py -v)",
      "Bash(python -c \"\ntext1 = ''This is a test chapter with fifteen words in total, making it long enough for validation.''\ntext2 = ''This text is long enough to pass the character validation even if the word count is very different.''\nprint(f''Text 1 length: {len(text1)} characters'')\nprint(f''Text 1 words: {len(text1.split())} words'')\nprint()\nprint(f''Text 2 length: {len(text2)} characters'')\nprint(f''Text 2 words: {len(text2.split())} words'')\n\")",
      "Bash(python -c \"\n# Test the actual flow\nfrom Writer.Scene.ChapterOutlineToScenes import ChapterOutlineToScenes\nfrom Writer.Scene.ScenesToJSON import ScenesToJSON\n\n# Check what each function returns\nimport inspect\nprint(''ChapterOutlineToScenes signature:'')\nprint(inspect.signature(ChapterOutlineToScenes))\nprint()\nprint(''ScenesToJSON signature:'')\nprint(inspect.signature(ScenesToJSON))\n\")",
      "Bash(python -m pytest tests/writer/test_scene_pipeline_optimization.py::test_scenes_to_json_input_output -v)",
      "Bash(python -m pytest tests/writer/test_scene_pipeline_optimization.py::test_scene_deduplication -v)",
      "Bash(python -m pytest tests/writer/test_scene_pipeline_optimization.py -v)",
      "Bash(pyright Writer/Scene/ScenesToJSON.py)",
      "Bash(flake8 Writer/Scene/ScenesToJSON.py --ignore=E501,W504,W503)",
      "Bash(python -m pytest tests/writer/test_lorebook_deprecation.py tests/writer/interface/test_json_output_display.py tests/writer/test_language_prompt_usage.py tests/writer/test_word_count_validation.py tests/writer/test_scene_pipeline_optimization.py -v --tb=short)"
    ],
    "deny": []
  }
}
